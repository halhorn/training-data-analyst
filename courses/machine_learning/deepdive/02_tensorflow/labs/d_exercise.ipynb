{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Unlike in the challenge exercise for c_estimator.ipynb, assume that your measurements of r, h and V are all rounded off to the nearest 0.1. Simulate the necessary training dataset. This time, you will need a lot more data to get a good predictor.\n",
    "\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "Create random values for r and h and compute V. Then, round off r, h and V (i.e., the volume is computed from the true value of r and h; it's only your measurement that is rounded off). Your dataset will consist of the round values of r, h and V. Do this for both the training and evaluation datasets.\n",
    "</p>\n",
    "\n",
    "Now modify the \"noise\" so that instead of just rounding off the value, there is up to a 10% error (uniformly distributed) in the measurement followed by rounding off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def add_round_noise(v: float) -> float:\n",
    "    return math.floor(v * 10 + 0.5) / 10\n",
    "\n",
    "def volume(r: float, h: float) -> float:\n",
    "    return add_round_noise(math.pi * r ** 2 * h)\n",
    "\n",
    "volume(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2742404469366355, 2.2051396315068557, 1.9081067880572844]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rand(data_size, min_val, max_val):\n",
    "    r = np.random.random(data_size)\n",
    "    return list((r + min_val) * (max_val - min_val))\n",
    "\n",
    "rand(3, 0.5, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(file_path, data_size):\n",
    "    df = pd.DataFrame({\n",
    "        'r': rand(train_data_size, 0.5, 2.0),\n",
    "        'h': rand(train_data_size, 0.5, 2.0),\n",
    "    })\n",
    "    df['v'] = df.apply(lambda x: volume(x['r'], x['h']), axis=1)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = 100000\n",
    "train_csv_path = 'cylinder_train.csv'\n",
    "eval_data_size = 1000\n",
    "eval_csv_path = 'cylinder_eval.csv'\n",
    "\n",
    "create_data(train_csv_path, train_data_size)\n",
    "create_data(eval_csv_path, eval_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h,r,v\n",
      "1.696460927899504,1.6230925450593552,14.0\n",
      "2.0359477976286646,1.5057178587118276,14.5\n",
      "0.9006614468655583,1.0591731938427562,3.2\n",
      "1.4151538120003724,1.9466229873368162,16.8\n",
      "1.4948395876296874,0.8571580037105848,3.5\n",
      "2.052116860978505,1.593828024225184,16.4\n",
      "1.7112787281230688,1.610704828978848,13.9\n",
      "1.180002745604126,1.180618590214592,5.2\n",
      "1.7225918047720534,0.8837887689581585,4.2\n"
     ]
    }
   ],
   "source": [
    "!head 'cylinder_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h,r,v\n",
      "0.888658107415006,1.550455670358788,6.7\n",
      "1.910877694137314,1.1957766222808017,8.6\n",
      "1.924271372383691,0.9403067950068089,5.3\n",
      "1.0671182789484401,1.7583366830839484,10.4\n",
      "0.9196097568858635,1.7855797677458498,9.2\n",
      "1.6183310587875859,1.9954173688282038,20.2\n",
      "1.110292591661596,1.874900388051557,12.3\n",
      "1.459788824484539,1.2149361556919744,6.8\n",
      "1.6461979292623592,1.123337340116479,6.5\n"
     ]
    }
   ],
   "source": [
    "!head 'cylinder_eval.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'h': <tf.Tensor: id=4, shape=(), dtype=float32, numpy=1.0>,\n",
       "  'r': <tf.Tensor: id=5, shape=(), dtype=float32, numpy=2.0>},\n",
       " <tf.Tensor: id=6, shape=(), dtype=float32, numpy=3.0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_NAMES = ['h', 'r']\n",
    "\n",
    "def parse_row(row: str) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "    cols = tf.decode_csv(row, record_defaults=[0.0, 0.0, 0.0])\n",
    "    label = cols.pop()\n",
    "    features = dict(zip(FEATURE_NAMES, cols))\n",
    "    return features, label\n",
    "\n",
    "parse_row('1.0, 2.0, 3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_input_fn(path, batch_size = 128):\n",
    "    dataset = tf.data.TextLineDataset(path).skip(1).map(parse_row).cache()\n",
    "    return dataset.repeat().shuffle(1024).batch(batch_size)\n",
    "\n",
    "def eval_input_fn(path, batch_size = 128):\n",
    "    return tf.data.TextLineDataset(path).skip(1).map(parse_row).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'h': <tf.Tensor: id=51, shape=(2,), dtype=float32, numpy=array([0.9521232, 1.8231676], dtype=float32)>,\n",
       "  'r': <tf.Tensor: id=52, shape=(2,), dtype=float32, numpy=array([2.0135014, 1.4123929], dtype=float32)>},\n",
       " <tf.Tensor: id=53, shape=(2,), dtype=float32, numpy=array([12.1, 11.4], dtype=float32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(training_input_fn(train_csv_path, batch_size=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'h': <tf.Tensor: id=89, shape=(2,), dtype=float32, numpy=array([0.8886581, 1.9108777], dtype=float32)>,\n",
       "  'r': <tf.Tensor: id=90, shape=(2,), dtype=float32, numpy=array([1.5504557, 1.1957766], dtype=float32)>},\n",
       " <tf.Tensor: id=91, shape=(2,), dtype=float32, numpy=array([6.7, 8.6], dtype=float32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(eval_input_fn(eval_csv_path, batch_size=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_num_ps_replicas': 0, '_model_dir': 'cy_model', '_service': None, '_device_fn': None, '_experimental_max_worker_delay_secs': None, '_is_chief': True, '_task_id': 0, '_experimental_distribute': None, '_evaluation_master': '', '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_protocol': None, '_train_distribute': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_master': '', '_tf_random_seed': 1, '_session_creation_timeout_secs': 7200, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc2d93a71d0>, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(name) for name in FEATURE_NAMES]\n",
    "model_dir = 'cy_model'\n",
    "lr = 0.001\n",
    "\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = tf.estimator.DNNRegressor(\n",
    "    hidden_units=[128, 128],\n",
    "    feature_columns=feature_columns,\n",
    "    model_dir=model_dir,\n",
    "    optimizer=tf.train.AdamOptimizer(lr),\n",
    "    config=tf.estimator.RunConfig(tf_random_seed=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from cy_model/model.ckpt-1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into cy_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 22.795193, step = 1000\n",
      "INFO:tensorflow:global_step/sec: 126.673\n",
      "INFO:tensorflow:loss = 13.352621, step = 1100 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.247\n",
      "INFO:tensorflow:loss = 8.445463, step = 1200 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.405\n",
      "INFO:tensorflow:loss = 8.710244, step = 1300 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.625\n",
      "INFO:tensorflow:loss = 5.968074, step = 1400 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.454\n",
      "INFO:tensorflow:loss = 5.1130958, step = 1500 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.254\n",
      "INFO:tensorflow:loss = 3.7761745, step = 1600 (0.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.613\n",
      "INFO:tensorflow:loss = 2.592925, step = 1700 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.34\n",
      "INFO:tensorflow:loss = 5.712787, step = 1800 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.573\n",
      "INFO:tensorflow:loss = 3.805241, step = 1900 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.004\n",
      "INFO:tensorflow:loss = 2.0025644, step = 2000 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.681\n",
      "INFO:tensorflow:loss = 2.8401632, step = 2100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.458\n",
      "INFO:tensorflow:loss = 1.88416, step = 2200 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.146\n",
      "INFO:tensorflow:loss = 2.9074826, step = 2300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.274\n",
      "INFO:tensorflow:loss = 1.6060612, step = 2400 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.766\n",
      "INFO:tensorflow:loss = 2.1795495, step = 2500 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.974\n",
      "INFO:tensorflow:loss = 0.9934451, step = 2600 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.235\n",
      "INFO:tensorflow:loss = 1.3590018, step = 2700 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.967\n",
      "INFO:tensorflow:loss = 2.149664, step = 2800 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.424\n",
      "INFO:tensorflow:loss = 0.91869, step = 2900 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.782\n",
      "INFO:tensorflow:loss = 0.60706526, step = 3000 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.519\n",
      "INFO:tensorflow:loss = 0.9521181, step = 3100 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.038\n",
      "INFO:tensorflow:loss = 1.3697647, step = 3200 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.529\n",
      "INFO:tensorflow:loss = 0.7876761, step = 3300 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.75\n",
      "INFO:tensorflow:loss = 0.831414, step = 3400 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.797\n",
      "INFO:tensorflow:loss = 1.6570318, step = 3500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.724\n",
      "INFO:tensorflow:loss = 0.7416793, step = 3600 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.892\n",
      "INFO:tensorflow:loss = 0.7661457, step = 3700 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.863\n",
      "INFO:tensorflow:loss = 0.5453784, step = 3800 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.036\n",
      "INFO:tensorflow:loss = 0.70497614, step = 3900 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.635\n",
      "INFO:tensorflow:loss = 0.5737265, step = 4000 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.277\n",
      "INFO:tensorflow:loss = 1.3129895, step = 4100 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.035\n",
      "INFO:tensorflow:loss = 0.4959284, step = 4200 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.885\n",
      "INFO:tensorflow:loss = 0.57827044, step = 4300 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.36\n",
      "INFO:tensorflow:loss = 0.59576046, step = 4400 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.023\n",
      "INFO:tensorflow:loss = 0.6121298, step = 4500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.855\n",
      "INFO:tensorflow:loss = 0.65184575, step = 4600 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.601\n",
      "INFO:tensorflow:loss = 0.79321325, step = 4700 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.465\n",
      "INFO:tensorflow:loss = 0.39093253, step = 4800 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.666\n",
      "INFO:tensorflow:loss = 0.8710744, step = 4900 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.524\n",
      "INFO:tensorflow:loss = 0.6579869, step = 5000 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.815\n",
      "INFO:tensorflow:loss = 0.80582285, step = 5100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.892\n",
      "INFO:tensorflow:loss = 0.5671014, step = 5200 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.436\n",
      "INFO:tensorflow:loss = 0.4876614, step = 5300 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.095\n",
      "INFO:tensorflow:loss = 0.6269958, step = 5400 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.743\n",
      "INFO:tensorflow:loss = 0.6429879, step = 5500 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.054\n",
      "INFO:tensorflow:loss = 0.41486803, step = 5600 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.593\n",
      "INFO:tensorflow:loss = 0.41345268, step = 5700 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.121\n",
      "INFO:tensorflow:loss = 0.86468387, step = 5800 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.926\n",
      "INFO:tensorflow:loss = 0.3943336, step = 5900 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.494\n",
      "INFO:tensorflow:loss = 0.5814699, step = 6000 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.613\n",
      "INFO:tensorflow:loss = 0.35881057, step = 6100 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.797\n",
      "INFO:tensorflow:loss = 0.5723247, step = 6200 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.67\n",
      "INFO:tensorflow:loss = 0.40757906, step = 6300 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.273\n",
      "INFO:tensorflow:loss = 0.3826474, step = 6400 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.299\n",
      "INFO:tensorflow:loss = 0.5307189, step = 6500 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.046\n",
      "INFO:tensorflow:loss = 0.64328235, step = 6600 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.192\n",
      "INFO:tensorflow:loss = 0.36136568, step = 6700 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.87\n",
      "INFO:tensorflow:loss = 0.46914393, step = 6800 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.288\n",
      "INFO:tensorflow:loss = 0.65659374, step = 6900 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.658\n",
      "INFO:tensorflow:loss = 0.6718935, step = 7000 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.012\n",
      "INFO:tensorflow:loss = 0.5286443, step = 7100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.716\n",
      "INFO:tensorflow:loss = 0.66247183, step = 7200 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.613\n",
      "INFO:tensorflow:loss = 0.34805945, step = 7300 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.847\n",
      "INFO:tensorflow:loss = 0.46595347, step = 7400 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.128\n",
      "INFO:tensorflow:loss = 0.26789102, step = 7500 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.832\n",
      "INFO:tensorflow:loss = 0.34330642, step = 7600 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.938\n",
      "INFO:tensorflow:loss = 0.36962667, step = 7700 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.778\n",
      "INFO:tensorflow:loss = 0.5108392, step = 7800 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.176\n",
      "INFO:tensorflow:loss = 0.25151625, step = 7900 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.95\n",
      "INFO:tensorflow:loss = 0.7833703, step = 8000 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.273\n",
      "INFO:tensorflow:loss = 0.2900566, step = 8100 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.146\n",
      "INFO:tensorflow:loss = 0.26105326, step = 8200 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.534\n",
      "INFO:tensorflow:loss = 0.43221003, step = 8300 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.65\n",
      "INFO:tensorflow:loss = 0.3274681, step = 8400 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.494\n",
      "INFO:tensorflow:loss = 1.0966439, step = 8500 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.396\n",
      "INFO:tensorflow:loss = 0.4113698, step = 8600 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.812\n",
      "INFO:tensorflow:loss = 0.3718038, step = 8700 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.404\n",
      "INFO:tensorflow:loss = 0.28069246, step = 8800 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.154\n",
      "INFO:tensorflow:loss = 0.3732893, step = 8900 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.222\n",
      "INFO:tensorflow:loss = 0.34463304, step = 9000 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.917\n",
      "INFO:tensorflow:loss = 1.1848905, step = 9100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.865\n",
      "INFO:tensorflow:loss = 0.42874053, step = 9200 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.571\n",
      "INFO:tensorflow:loss = 0.31405032, step = 9300 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.156\n",
      "INFO:tensorflow:loss = 0.81694293, step = 9400 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.566\n",
      "INFO:tensorflow:loss = 0.31136698, step = 9500 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.538\n",
      "INFO:tensorflow:loss = 0.38613552, step = 9600 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.802\n",
      "INFO:tensorflow:loss = 0.488002, step = 9700 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.3\n",
      "INFO:tensorflow:loss = 0.23465633, step = 9800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.674\n",
      "INFO:tensorflow:loss = 0.33910698, step = 9900 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.515\n",
      "INFO:tensorflow:loss = 0.5361598, step = 10000 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.045\n",
      "INFO:tensorflow:loss = 0.39903218, step = 10100 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.394\n",
      "INFO:tensorflow:loss = 0.4429531, step = 10200 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.369\n",
      "INFO:tensorflow:loss = 0.57787067, step = 10300 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.802\n",
      "INFO:tensorflow:loss = 0.32872415, step = 10400 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.215\n",
      "INFO:tensorflow:loss = 0.49650466, step = 10500 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.867\n",
      "INFO:tensorflow:loss = 0.39149705, step = 10600 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.544\n",
      "INFO:tensorflow:loss = 0.43172342, step = 10700 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.64\n",
      "INFO:tensorflow:loss = 0.3037708, step = 10800 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.147\n",
      "INFO:tensorflow:loss = 0.30374062, step = 10900 (0.228 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into cy_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.36194673.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7fc2d93e4668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(lambda: training_input_fn(train_csv_path, batch_size=128), steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-21T13:48:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from cy_model/model.ckpt-11000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-21-13:48:41\n",
      "INFO:tensorflow:Saving dict for global step 11000: average_loss = 0.002301367, global_step = 11000, label/mean = 11.455752, loss = 0.29429245, prediction/mean = 11.459977\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11000: cy_model/model.ckpt-11000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04797256507364776"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.evaluate(lambda: eval_input_fn(eval_csv_path))\n",
    "metrics['average_loss']**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
